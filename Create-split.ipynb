{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1267980-bfce-4661-b3bb-ceb837ed778e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run 000 of 030 ---\n",
      "Running: Activation=LSGELUS300 at 2025-09-15 17:01:47\n",
      "Epoch 1/101\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - accuracy: 0.3369 - loss: 2.1706 - val_accuracy: 0.4385 - val_loss: 1.5940\n",
      "Epoch 2/101\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - accuracy: 0.4716 - loss: 1.5188 - val_accuracy: 0.4692 - val_loss: 1.5022\n",
      "Epoch 3/101\n",
      "\u001b[1m431/782\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.5219 - loss: 1.3542"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 226\u001b[39m\n\u001b[32m    221\u001b[39m model = build_model(act_fn)\n\u001b[32m    222\u001b[39m model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=\u001b[32m0.001\u001b[39m),\n\u001b[32m    223\u001b[39m                     loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    224\u001b[39m                     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning: Activation=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mact_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.datetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)   \n\u001b[32m    229\u001b[39m results[act_name] = {key: np.array(val) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m history.history.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:322\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    320\u001b[39m logs = \u001b[38;5;28mself\u001b[39m.train_function(iterator)\n\u001b[32m    321\u001b[39m logs = \u001b[38;5;28mself\u001b[39m._pythonify_logs(logs)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\callback_list.py:106\u001b[39m, in \u001b[36mCallbackList.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    104\u001b[39m logs = logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mcallback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:58\u001b[39m, in \u001b[36mProgbarLogger.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:95\u001b[39m, in \u001b[36mProgbarLogger._update_progbar\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\progbar.py:182\u001b[39m, in \u001b[36mProgbar.update\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m finalize:\n\u001b[32m    180\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[43mio_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28mself\u001b[39m._prev_total_width = total_width\n\u001b[32m    184\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\io_utils.py:99\u001b[39m, in \u001b[36mprint_msg\u001b[39m\u001b[34m(message, line_break)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     98\u001b[39m         sys.stdout.write(message)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    101\u001b[39m     logging.info(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\iostream.py:609\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(evt.set)\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIOStream.flush timed out\u001b[39m\u001b[33m\"\u001b[39m, file=sys.__stderr__)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#--- 2025-09-15 16-32 – by Dr. Thawatchai Chomsiri\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "  \n",
    "#def lsgelu(x):    # Left-Shifted GELU with 1 range\n",
    "#    return x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus300(x):    \n",
    "    S=3.00\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus270(x):    \n",
    "    S=2.70\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus240(x):    \n",
    "    S=2.40\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus210(x):    \n",
    "    S=2.10\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus180(x):    \n",
    "    S=1.80\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus150(x):    # LSGELU   \n",
    "    S=1.50\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus120(x):    \n",
    "    S=1.20\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus090(x):    \n",
    "    S=0.90\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus060(x):    \n",
    "    S=0.60\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus030(x):    \n",
    "    S=0.30\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus000(x):    # GELU    \n",
    "    S=0.00\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def lsgelu9999(x):    \n",
    "    S=3.71901648546\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9950(x):    \n",
    "    S=2.57582930355\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9900(x):    \n",
    "    S=2.32634787404\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9750(x):    \n",
    "    S=1.95996398454\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9500(x):    \n",
    "    S=1.64485362695\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu9332(x): # LSGELU   \n",
    "    S=1.5\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu9250(x):    \n",
    "    S=1.43953147094\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9000(x):    \n",
    "    S=1.28155156554\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu8000(x):    \n",
    "    S=0.841621233573\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu7500(x):    \n",
    "    S=0.674489750196\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu6666(x):    \n",
    "    S=0.430727299295\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu2(x):    # Left-Shifted GELU with 2 range\n",
    "    return tf.where(\n",
    "        x >= 0,\n",
    "        x, \n",
    "        x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0)))\n",
    "    ) \n",
    "\n",
    "def lsgelu3(x):    # Left-Shifted GELU with 3 range\n",
    "    L = -3.00\n",
    "    return tf.where(\n",
    "        x >= 0,\n",
    "        x,\n",
    "        tf.where(\n",
    "            x >= L,\n",
    "            x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0))),\n",
    "            tf.zeros_like(x)\n",
    "        )\n",
    "    ) \n",
    "\n",
    "# Function สำหรับสร้างโมเดล\n",
    "def build_model(activation_fn):\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(32, (3, 3), strides=2, padding='same', activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation_fn)(x)\n",
    "\n",
    "    def bottleneck_block(x, filters):\n",
    "        dw = DepthwiseConv2D((3, 3), padding='same')(x)\n",
    "        dw = BatchNormalization()(dw)\n",
    "        dw = Activation(activation_fn)(dw)\n",
    "\n",
    "        pw = Conv2D(filters, (1, 1), padding='same')(dw)\n",
    "        pw = BatchNormalization()(pw)\n",
    "        pw = Activation(activation_fn)(pw)\n",
    "        return pw\n",
    "\n",
    "    x = bottleneck_block(x, 64)\n",
    "    x = bottleneck_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = bottleneck_block(x, 128)\n",
    "    x = bottleneck_block(x, 128)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same', activation=activation_fn)(inputs)  # ชั้น Conv2D\n",
    "    x = Flatten()(x)  # แปลงการ output ของ Conv2D ให้เป็น 1 มิติ\n",
    "    x = Dense(128, activation=activation_fn)(x)  # ชั้น Hidden Layer ที่มี 128 โหนด\n",
    "    \n",
    "    outputs = Dense(10, activation='softmax')(x)  # ชั้น Output Layer\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "activations_list = {\n",
    "    \"LSGELUS300\": lsgelus300,\n",
    "    \"LSGELUS270\": lsgelus270,\n",
    "    \"LSGELUS240\": lsgelus240,\n",
    "    \"LSGELUS210\": lsgelus210,\n",
    "    \"LSGELUS180\": lsgelus180,\n",
    "    \"LSGELUS150\": lsgelus150,  # LSGELU\n",
    "    \"LSGELUS120\": lsgelus120,\n",
    "    \"LSGELUS090\": lsgelus090,\n",
    "    \"LSGELUS060\": lsgelus060,\n",
    "    \"LSGELUS030\": lsgelus030,\n",
    "    \"LSGELUS000\": lsgelus000,   # GELU\n",
    "    \n",
    "    'GELU': tf.nn.gelu,\n",
    "    'ELU': tf.nn.elu,\n",
    "    'ReLU': tf.nn.relu,\n",
    "    'Swish': tf.nn.swish,     \n",
    "}\n",
    "\n",
    "epochs = 101  ################\n",
    "num_runs = 30 ###############\n",
    "batch_size = 64 ###############\n",
    "results = {\n",
    "    'activation': [],\n",
    "    'accuracy_per_epoch': []\n",
    "}\n",
    "accuracy_summary = {}\n",
    "\n",
    "for run_idx in range(num_runs):\n",
    "    print(f\"\\n--- Run {run_idx:03d} of {num_runs:03d} ---\")\n",
    "    results = {}\n",
    "    accuracy_results = {}\n",
    "    loss_results = {}\n",
    "    \n",
    "    for act_name, act_fn in activations_list.items():\n",
    "        print(f\"Running: Activation={act_name} at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        # เทรน\n",
    "        model = build_model(act_fn)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                            loss='sparse_categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), batch_size=batch_size)\n",
    "        \n",
    "        print(f\"Running: Activation={act_name} at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")   \n",
    "        results[act_name] = {key: np.array(val) for key, val in history.history.items()}\n",
    "        print(f\"Details in results for round {run_idx:03d}:\")\n",
    "        for act_name, metrics_dict in results.items():\n",
    "            print(f\"\\nActivation: {act_name}\")\n",
    "            for metric_name, metric_values in metrics_dict.items():\n",
    "                print(f\"  {metric_name}: {metric_values}\")\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.figure(figsize=(15,8))\n",
    "        for key, hist_vals in results.items():\n",
    "            plt.plot(hist_vals['accuracy'], label=key)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        # Plot Loss\n",
    "        plt.figure(figsize=(15,8))\n",
    "        for key, hist_vals in results.items():\n",
    "            plt.plot(hist_vals['loss'], label=key)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        np.savez(f\"accuracy_{run_idx:03d}_{act_name}.npz\", accuracy=np.array(history.history['accuracy']))\n",
    "        np.savez(f\"loss_{run_idx:03d}_{act_name}.npz\", loss=np.array(history.history['loss']))\n",
    "        \n",
    "        accuracy_results[act_name] = np.array(history.history['accuracy'])\n",
    "        loss_results[act_name] = np.array(history.history['loss'])\n",
    "\n",
    "    print(f\" ----- Data -------- \")\n",
    "    results[act_name] = {key: np.array(val) for key, val in history.history.items()}\n",
    "    print(f\"Details in results for round {run_idx:03d}:\")\n",
    "    for act_name, metrics_dict in results.items():\n",
    "        print(f\"\\nActivation: {act_name}\")\n",
    "        for metric_name, metric_values in metrics_dict.items():\n",
    "            print(f\"  {metric_name}: {metric_values}\")\n",
    "\n",
    "    print(f\" ------------------- \")\n",
    "    ###np.savez(f\"accuracy_{run_idx:03d}.npz\", **accuracy_results)\n",
    "    ###np.savez(f\"loss_{run_idx:03d}.npz\", **loss_results)\n",
    "\n",
    "folder_path = '.'\n",
    "accuracy_files = sorted([f for f in os.listdir(folder_path) if re.match(r'accuracy_\\d+\\.npz', f)])\n",
    "loss_files = sorted([f for f in os.listdir(folder_path) if re.match(r'loss_\\d+\\.npz', f)])\n",
    "\n",
    "accuracy_collections = {}\n",
    "for fname in accuracy_files:\n",
    "    acc_data = np.load(os.path.join(folder_path, fname), allow_pickle=True)\n",
    "    for key in acc_data.files:\n",
    "        if key not in accuracy_collections:\n",
    "            accuracy_collections[key] = []\n",
    "        accuracy_collections[key].append(acc_data[key])\n",
    "\n",
    "accuracy_avg = {}\n",
    "for act_name, vals in accuracy_collections.items():\n",
    "    stacked = np.vstack(vals)\n",
    "    accuracy_avg[act_name] = np.mean(stacked, axis=0)\n",
    "\n",
    "loss_collections = {}\n",
    "for fname in loss_files:\n",
    "    los_data = np.load(os.path.join(folder_path, fname), allow_pickle=True)\n",
    "    for key in los_data.files:\n",
    "        if key not in loss_collections:\n",
    "            loss_collections[key] = []\n",
    "        loss_collections[key].append(los_data[key])\n",
    "\n",
    "loss_avg = {}\n",
    "for act_name, vals in loss_collections.items():\n",
    "    stacked = np.vstack(vals)\n",
    "    loss_avg[act_name] = np.mean(stacked, axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, act_name in enumerate(accuracy_avg):\n",
    "    plt.plot(accuracy_avg[act_name], label=act_name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Accuracy of Activation Functions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, act_name in enumerate(loss_avg):\n",
    "    plt.plot(loss_avg[act_name], label=act_name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Average Loss of Activation Functions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(accuracy_files)):\n",
    "    fname_acc = accuracy_files[i]\n",
    "    fname_loss = loss_files[i]\n",
    "    print(f\"\\n--- Loading {fname_acc} and {fname_loss} ---\")\n",
    "    acc_data = np.load(os.path.join(folder_path, fname_acc), allow_pickle=True)\n",
    "    loss_data = np.load(os.path.join(folder_path, fname_loss), allow_pickle=True)\n",
    "\n",
    "    print(\"Keys accuracy:\", list(acc_data.keys()))\n",
    "    print(\"Keys loss:\", list(loss_data.keys()))\n",
    "\n",
    "    activation_names = list(acc_data.files)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(15,8))\n",
    "    for name in activation_names:\n",
    "        plt.plot(acc_data[name], label=name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy from {fname_acc}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(15,8))\n",
    "    for name in activation_names:\n",
    "        plt.plot(loss_data[name], label=name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss from {fname_loss}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "   \n",
    "print(f\"\\nEND at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf3b27-6261-406a-8a9d-0919fe44a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
