{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1267980-bfce-4661-b3bb-ceb837ed778e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run 000 of 030 ---\n",
      "Running: Activation=LSGELUS300 at 2025-09-15 17:01:47\n",
      "Epoch 1/101\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - accuracy: 0.3369 - loss: 2.1706 - val_accuracy: 0.4385 - val_loss: 1.5940\n",
      "Epoch 2/101\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - accuracy: 0.4716 - loss: 1.5188 - val_accuracy: 0.4692 - val_loss: 1.5022\n",
      "Epoch 3/101\n",
      "\u001b[1m353/782\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 54ms/step - accuracy: 0.5224 - loss: 1.3530"
     ]
    }
   ],
   "source": [
    "#--- 2025-09-15 16-32 – by Dr. Thawatchai Chomsiri\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "  \n",
    "#def lsgelu(x):    # Left-Shifted GELU with 1 range\n",
    "#    return x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus300(x):    \n",
    "    S=3.00\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus270(x):    \n",
    "    S=2.70\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus240(x):    \n",
    "    S=2.40\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus210(x):    \n",
    "    S=2.10\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus180(x):    \n",
    "    S=1.80\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus150(x):    # LSGELU   \n",
    "    S=1.50\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus120(x):    \n",
    "    S=1.20\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus090(x):    \n",
    "    S=0.90\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus060(x):    \n",
    "    S=0.60\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus030(x):    \n",
    "    S=0.30\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelus000(x):    # GELU    \n",
    "    S=0.00\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def lsgelu9999(x):    \n",
    "    S=3.71901648546\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9950(x):    \n",
    "    S=2.57582930355\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9900(x):    \n",
    "    S=2.32634787404\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9750(x):    \n",
    "    S=1.95996398454\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9500(x):    \n",
    "    S=1.64485362695\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu9332(x): # LSGELU   \n",
    "    S=1.5\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu9250(x):    \n",
    "    S=1.43953147094\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu9000(x):    \n",
    "    S=1.28155156554\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu8000(x):    \n",
    "    S=0.841621233573\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu7500(x):    \n",
    "    S=0.674489750196\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "def lsgelu6666(x):    \n",
    "    S=0.430727299295\n",
    "    return x * 0.5 * (1 + tf.math.erf((x + S) / tf.sqrt(2.0)))\n",
    "\n",
    "#-----\n",
    "def lsgelu2(x):    # Left-Shifted GELU with 2 range\n",
    "    return tf.where(\n",
    "        x >= 0,\n",
    "        x, \n",
    "        x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0)))\n",
    "    ) \n",
    "\n",
    "def lsgelu3(x):    # Left-Shifted GELU with 3 range\n",
    "    L = -3.00\n",
    "    return tf.where(\n",
    "        x >= 0,\n",
    "        x,\n",
    "        tf.where(\n",
    "            x >= L,\n",
    "            x * 0.5 * (1 + tf.math.erf((x + 1.5) / tf.sqrt(2.0))),\n",
    "            tf.zeros_like(x)\n",
    "        )\n",
    "    ) \n",
    "\n",
    "# Function สำหรับสร้างโมเดล\n",
    "def build_model(activation_fn):\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(32, (3, 3), strides=2, padding='same', activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation_fn)(x)\n",
    "\n",
    "    def bottleneck_block(x, filters):\n",
    "        dw = DepthwiseConv2D((3, 3), padding='same')(x)\n",
    "        dw = BatchNormalization()(dw)\n",
    "        dw = Activation(activation_fn)(dw)\n",
    "\n",
    "        pw = Conv2D(filters, (1, 1), padding='same')(dw)\n",
    "        pw = BatchNormalization()(pw)\n",
    "        pw = Activation(activation_fn)(pw)\n",
    "        return pw\n",
    "\n",
    "    x = bottleneck_block(x, 64)\n",
    "    x = bottleneck_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = bottleneck_block(x, 128)\n",
    "    x = bottleneck_block(x, 128)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same', activation=activation_fn)(inputs)  # ชั้น Conv2D\n",
    "    x = Flatten()(x)  # แปลงการ output ของ Conv2D ให้เป็น 1 มิติ\n",
    "    x = Dense(128, activation=activation_fn)(x)  # ชั้น Hidden Layer ที่มี 128 โหนด\n",
    "    \n",
    "    outputs = Dense(10, activation='softmax')(x)  # ชั้น Output Layer\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "activations_list = {\n",
    "    \"LSGELUS300\": lsgelus300,\n",
    "    \"LSGELUS270\": lsgelus270,\n",
    "    \"LSGELUS240\": lsgelus240,\n",
    "    \"LSGELUS210\": lsgelus210,\n",
    "    \"LSGELUS180\": lsgelus180,\n",
    "    \"LSGELUS150\": lsgelus150,  # LSGELU\n",
    "    \"LSGELUS120\": lsgelus120,\n",
    "    \"LSGELUS090\": lsgelus090,\n",
    "    \"LSGELUS060\": lsgelus060,\n",
    "    \"LSGELUS030\": lsgelus030,\n",
    "    \"LSGELUS000\": lsgelus000,   # GELU\n",
    "    \n",
    "    'GELU': tf.nn.gelu,\n",
    "    'ELU': tf.nn.elu,\n",
    "    'ReLU': tf.nn.relu,\n",
    "    'Swish': tf.nn.swish,     \n",
    "}\n",
    "\n",
    "epochs = 101  ################\n",
    "num_runs = 30 ###############\n",
    "batch_size = 64 ###############\n",
    "results = {\n",
    "    'activation': [],\n",
    "    'accuracy_per_epoch': []\n",
    "}\n",
    "accuracy_summary = {}\n",
    "\n",
    "for run_idx in range(num_runs):\n",
    "    print(f\"\\n--- Run {run_idx:03d} of {num_runs:03d} ---\")\n",
    "    results = {}\n",
    "    accuracy_results = {}\n",
    "    loss_results = {}\n",
    "    \n",
    "    for act_name, act_fn in activations_list.items():\n",
    "        print(f\"Running: Activation={act_name} at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        # เทรน\n",
    "        model = build_model(act_fn)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                            loss='sparse_categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), batch_size=batch_size)\n",
    "        \n",
    "        print(f\"Running: Activation={act_name} at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")   \n",
    "        results[act_name] = {key: np.array(val) for key, val in history.history.items()}\n",
    "        print(f\"Details in results for round {run_idx:03d}:\")\n",
    "        for act_name, metrics_dict in results.items():\n",
    "            print(f\"\\nActivation: {act_name}\")\n",
    "            for metric_name, metric_values in metrics_dict.items():\n",
    "                print(f\"  {metric_name}: {metric_values}\")\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.figure(figsize=(15,8))\n",
    "        for key, hist_vals in results.items():\n",
    "            plt.plot(hist_vals['accuracy'], label=key)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        # Plot Loss\n",
    "        plt.figure(figsize=(15,8))\n",
    "        for key, hist_vals in results.items():\n",
    "            plt.plot(hist_vals['loss'], label=key)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        np.savez(f\"accuracy_{run_idx:03d}_{act_name}.npz\", accuracy=np.array(history.history['accuracy']))\n",
    "        np.savez(f\"loss_{run_idx:03d}_{act_name}.npz\", loss=np.array(history.history['loss']))\n",
    "        \n",
    "        accuracy_results[act_name] = np.array(history.history['accuracy'])\n",
    "        loss_results[act_name] = np.array(history.history['loss'])\n",
    "\n",
    "    print(f\" ----- Data -------- \")\n",
    "    results[act_name] = {key: np.array(val) for key, val in history.history.items()}\n",
    "    print(f\"Details in results for round {run_idx:03d}:\")\n",
    "    for act_name, metrics_dict in results.items():\n",
    "        print(f\"\\nActivation: {act_name}\")\n",
    "        for metric_name, metric_values in metrics_dict.items():\n",
    "            print(f\"  {metric_name}: {metric_values}\")\n",
    "\n",
    "    print(f\" ------------------- \")\n",
    "    ###np.savez(f\"accuracy_{run_idx:03d}.npz\", **accuracy_results)\n",
    "    ###np.savez(f\"loss_{run_idx:03d}.npz\", **loss_results)\n",
    "\n",
    "folder_path = '.'\n",
    "accuracy_files = sorted([f for f in os.listdir(folder_path) if re.match(r'accuracy_\\d+\\.npz', f)])\n",
    "loss_files = sorted([f for f in os.listdir(folder_path) if re.match(r'loss_\\d+\\.npz', f)])\n",
    "\n",
    "accuracy_collections = {}\n",
    "for fname in accuracy_files:\n",
    "    acc_data = np.load(os.path.join(folder_path, fname), allow_pickle=True)\n",
    "    for key in acc_data.files:\n",
    "        if key not in accuracy_collections:\n",
    "            accuracy_collections[key] = []\n",
    "        accuracy_collections[key].append(acc_data[key])\n",
    "\n",
    "accuracy_avg = {}\n",
    "for act_name, vals in accuracy_collections.items():\n",
    "    stacked = np.vstack(vals)\n",
    "    accuracy_avg[act_name] = np.mean(stacked, axis=0)\n",
    "\n",
    "loss_collections = {}\n",
    "for fname in loss_files:\n",
    "    los_data = np.load(os.path.join(folder_path, fname), allow_pickle=True)\n",
    "    for key in los_data.files:\n",
    "        if key not in loss_collections:\n",
    "            loss_collections[key] = []\n",
    "        loss_collections[key].append(los_data[key])\n",
    "\n",
    "loss_avg = {}\n",
    "for act_name, vals in loss_collections.items():\n",
    "    stacked = np.vstack(vals)\n",
    "    loss_avg[act_name] = np.mean(stacked, axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, act_name in enumerate(accuracy_avg):\n",
    "    plt.plot(accuracy_avg[act_name], label=act_name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Accuracy of Activation Functions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, act_name in enumerate(loss_avg):\n",
    "    plt.plot(loss_avg[act_name], label=act_name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Average Loss of Activation Functions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(accuracy_files)):\n",
    "    fname_acc = accuracy_files[i]\n",
    "    fname_loss = loss_files[i]\n",
    "    print(f\"\\n--- Loading {fname_acc} and {fname_loss} ---\")\n",
    "    acc_data = np.load(os.path.join(folder_path, fname_acc), allow_pickle=True)\n",
    "    loss_data = np.load(os.path.join(folder_path, fname_loss), allow_pickle=True)\n",
    "\n",
    "    print(\"Keys accuracy:\", list(acc_data.keys()))\n",
    "    print(\"Keys loss:\", list(loss_data.keys()))\n",
    "\n",
    "    activation_names = list(acc_data.files)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(15,8))\n",
    "    for name in activation_names:\n",
    "        plt.plot(acc_data[name], label=name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy from {fname_acc}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(15,8))\n",
    "    for name in activation_names:\n",
    "        plt.plot(loss_data[name], label=name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss from {fname_loss}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "   \n",
    "print(f\"\\nEND at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf3b27-6261-406a-8a9d-0919fe44a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
